\begin{abstract}
% Overcooked is a classic multi-agent cooperative game scenario. Existing simulation environments utilize simplified game settings to achieve cooperation between agents as well as human-agent collaboration tasks. However, these environments lack key features present in the real Overcooked game, such as ingredient synthesis, four-player cooperation and the most important, dynamic objectives. As a result, in Overcooked, a bounded-reward environment, the performance of agents has little improvement margin, which is detrimental to research in multi-agent reinforcement learning. 
Recent advancements in cooperative multi-agent systems have led to significant updates in both environments and algorithms. However, current cooperative multi-agent reinforcement learning (MARL) environments predominantly focus on single-objective tasks, where agents optimize their policies toward single static objectives. For instance, in the \textit{Overcooked\_AI} environment, agents are tasked with delivering as many orders as possible within a limited time, without considering the actual demand or necessity of these orders by users. This contrasts sharply with the real-world Overcooked game scenario, where the primary challenge lies in fulfilling dynamic user orders promptly. To address this gap, we introduce \textit{ComplexOvercooked}, a novel MARL environment designed to better simulate real-world complexities. This environment features a highly configurable layout, dynamically generated user order demands, and supports three distinct control interfaces: human, model-based Large Language Models (LLM), and model-free Reinforcement Learning (RL) agents. By benchmarking classic MARL algorithms in \textit{ComplexOvercooked}, we not only highlight the potential for performance enhancement but also delineate the capability boundaries of MARL within this more intricate setting. We public the code of environment and MARL algorithms at https://anonymous.4open.science/r/ComplexOvercooked-1D82.
\end{abstract}