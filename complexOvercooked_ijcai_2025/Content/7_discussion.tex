\textbf{Conclusion} \ We have introduced an open-source RL environment \textit{ComplexOvercooked}. It is an easily configurable, expandable multi-agent environment, supporting up to four agents in cooperation. It boasts a user-friendly gaming interface and clear underlying game logic and can serve as a benchmark in the field of multi-agent collaboration. We then conducted experiments to validate the environment's usability by using baseline algorithms of MARL. We provide three types of interfaces (i.e., RL agents, humans, and LLM) to control the players, which provide convenience for some valuable future research directions.
\\
\textbf{Future Directions} \ A possible research direction is \textit{human-machine collaboration}. In this multi-task environment, due to the complexity of tasks, it is difficult for a single agent to be competent. Moreover, the workflow for completing tasks is variable. Human players may show behavioral preferences to complete tasks. Training cooperative agents to understand human intentions and to align with human values \cite{yuan2022situ} is worth researching. In fact, Overcooked game greatly necessitates dialogue and communication between players. Due to the urgency of time and orders, partners often need to communicate with each other to achieve better cooperation. Therefore, \textit{collaboration driven by LLMs} is a promising research direction\cite{wen2022multi,zhang2023proagent,zhu2023madiff},. Assisting reinforcement learning algorithms with LLMs could potentially accelerate their convergence. In a dynamic-objective system, \textit{task decomposition and subtask allocation} are also worth studying \cite{yang2022ldsa,iqbal2022alma}. We provide several well-defined tasks in the \textit{ComplexOvercooked}, and subsequent research can focus on enhancing the capabilities of agents in dynamic-objective scenarios.