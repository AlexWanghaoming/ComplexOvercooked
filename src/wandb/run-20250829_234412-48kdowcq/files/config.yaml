_wandb:
    value:
        cli_version: 0.19.1
        m: []
        python_version: 3.10.15
        t:
            "1":
                - 1
                - 52
                - 55
            "2":
                - 1
                - 52
                - 55
            "3":
                - 16
                - 23
                - 55
                - 61
            "4": 3.10.15
            "5": 0.19.1
            "8":
                - 5
            "12": 0.19.1
            "13": darwin-arm64
action_selector:
    value: epsilon_greedy
add_value_last_step:
    value: true
agent:
    value: rnn
agent_output_type:
    value: q
batch_size:
    value: 32
batch_size_run:
    value: 1
buffer_cpu_only:
    value: true
buffer_size:
    value: 5000
checkpoint_path:
    value: ""
common_reward:
    value: true
double_q:
    value: true
env:
    value: overcooked2
env_args:
    value:
        ifrender: false
        lossless_obs: false
        map_name: supereasy
        seed: 454305579
epsilon_anneal_time:
    value: 5000000
epsilon_finish:
    value: 0.05
epsilon_start:
    value: 1
evaluate:
    value: false
evaluation_epsilon:
    value: 0
gamma:
    value: 0.99
grad_norm_clip:
    value: 10
hidden_dim:
    value: 64
hypergroup:
    value: null
label:
    value: default_label
learner:
    value: q_learner
learner_log_interval:
    value: 6000
load_step:
    value: 0
local_results_path:
    value: results
log_interval:
    value: 6000
lr:
    value: 0.001
lr_decay:
    value: true
mac:
    value: basic_mac
mixer:
    value: null
name:
    value: iql
obs_agent_id:
    value: true
obs_individual_obs:
    value: false
obs_last_action:
    value: false
optim_alpha:
    value: 0.99
optim_eps:
    value: 1e-05
render:
    value: false
repeat_id:
    value: 1
reward_scalarisation:
    value: mean
reward_shaping_horizon:
    value: 1e+07
runner:
    value: episode
runner_log_interval:
    value: 6000
save_model:
    value: true
save_model_interval:
    value: 100000
save_replay:
    value: false
seed:
    value: 454305579
standardise_returns:
    value: false
standardise_rewards:
    value: false
t_max:
    value: 2e+07
target_update_interval_or_tau:
    value: 100
test_greedy:
    value: true
test_interval:
    value: 50000
test_nepisode:
    value: 3
use_cuda:
    value: false
use_rnn:
    value: true
use_tensorboard:
    value: false
use_wandb:
    value: true
wandb_mode:
    value: online
wandb_project:
    value: epymarl_overcooked2
wandb_save_model:
    value: false
wandb_team:
    value: wanghm
